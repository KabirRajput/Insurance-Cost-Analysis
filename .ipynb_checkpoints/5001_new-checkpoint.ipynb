{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow import feature_column\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = '4bf9de72-bf24-4d91-a718-11b60032a45f'\n",
    "resource_group = 'funghi'\n",
    "workspace_name = 'funghi-ml'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\n",
    "dataset = Dataset.get_by_name(workspace, name='5001_train_t')\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1318429 entries, (20050, 8610602) to (20071, 3778506)\n",
      "Data columns (total 36 columns):\n",
      "Row_ID            1318429 non-null int64\n",
      "Household_ID      1318429 non-null int64\n",
      "Vehicle           1318429 non-null int64\n",
      "Calendar_Year     1318429 non-null int64\n",
      "Model_Year        1318429 non-null int64\n",
      "Blind_Make        1318429 non-null object\n",
      "Blind_Model       1318429 non-null object\n",
      "Blind_Submodel    1318429 non-null object\n",
      "Cat1              1318429 non-null object\n",
      "Cat2              1318429 non-null object\n",
      "Cat3              1318429 non-null object\n",
      "Cat4              1318429 non-null object\n",
      "Cat5              1318429 non-null object\n",
      "Cat6              1318429 non-null object\n",
      "Cat7              1318429 non-null object\n",
      "Cat8              1318429 non-null object\n",
      "Cat9              1318429 non-null object\n",
      "Cat10             1318429 non-null object\n",
      "Cat11             1318429 non-null object\n",
      "Cat12             1318429 non-null object\n",
      "OrdCat            1317674 non-null float64\n",
      "Var1              1318429 non-null float64\n",
      "Var2              1318429 non-null float64\n",
      "Var3              1318429 non-null float64\n",
      "Var4              1318429 non-null float64\n",
      "Var5              1318429 non-null float64\n",
      "Var6              1318429 non-null float64\n",
      "Var7              1318429 non-null float64\n",
      "Var8              1318429 non-null float64\n",
      "NVCat             1318429 non-null object\n",
      "NVVar1            1318429 non-null float64\n",
      "NVVar2            1318429 non-null float64\n",
      "NVVar3            1318429 non-null float64\n",
      "NVVar4            1318429 non-null float64\n",
      "Claim_Amount      1318429 non-null float64\n",
      "Label             1318429 non-null int64\n",
      "dtypes: float64(14), int64(6), object(16)\n",
      "memory usage: 378.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df['Label'] = df['Claim_Amount'] > 0 \n",
    "df['Label'] = df['Calendar_Year'] * 10 + df['Label'].astype(int)\n",
    "df = df.groupby('Label').apply(lambda x: x.sample(frac=0.1))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['Cat1','Cat2','Cat3','Cat4','Cat5','Cat6','Cat7','Cat8','Cat9','Cat10','Cat11','Cat12']\n",
    "ncats = ['Vehicle','OrdCat','NVCat']\n",
    "nums = ['Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4']\n",
    "embedding = ['Blind_Make','Blind_Model','Blind_Submodel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cats:\n",
    "    df[c] = df[c].replace('?', None)\n",
    "    df[c] = df[c].replace('', None)\n",
    "    \n",
    "df['OrdCat'] = df['OrdCat'].fillna(value=0).apply(str).replace('0.0', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, stratify=df['Label'])\n",
    "train, val = train_test_split(train, test_size=0.2, stratify=train['Label'])\n",
    "\n",
    "train = train.drop(['Label','Household_ID','Row_ID'], axis=1)\n",
    "test = test.drop(['Label','Household_ID','Row_ID'], axis=1)\n",
    "val = val.drop(['Label','Household_ID','Row_ID'], axis=1)\n",
    "\n",
    "train_target = train.pop('Claim_Amount')\n",
    "val_target = val.pop('Claim_Amount')\n",
    "test_target = test.pop('Claim_Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_layer():\n",
    "    feature_columns = []\n",
    "    \n",
    "    for c in cats:\n",
    "        c_list = feature_column.categorical_column_with_vocabulary_list(c, df[c].unique())\n",
    "        feature_columns.append(feature_column.indicator_column(c_list))\n",
    "\n",
    "    for n in nums:\n",
    "        feature_columns.append(feature_column.numeric_column(n))\n",
    "\n",
    "    for n in ncats:\n",
    "        n_list = feature_column.categorical_column_with_vocabulary_list(n, df[n].unique())\n",
    "        feature_columns.append(feature_column.indicator_column(n_list))\n",
    "\n",
    "    for e in embedding:\n",
    "        v = df[e].unique()\n",
    "        l = feature_column.categorical_column_with_vocabulary_list(e, v)\n",
    "        feature_columns.append(feature_column.embedding_column(l, dimension=len(v)//10))\n",
    "        \n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "    \n",
    "    return feature_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        get_feature_layer(),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=L1L2(l1=0.0, l2=0.01)),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=L1L2(l1=0.0, l2=0.01)),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mae',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, labels, shuffle=True, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "train_ds = df_to_dataset(train, train_target)\n",
    "val_ds = df_to_dataset(val, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Layer sequential_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "26369/26369 [==============================] - 384s 15ms/step - loss: 1.3757 - mae: 1.3709 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00\n",
      "Epoch 2/3\n",
      "26369/26369 [==============================] - 360s 14ms/step - loss: 1.3708 - mae: 1.3707 - val_loss: 1.4412 - val_mae: 1.4414\n",
      "Epoch 3/3\n",
      "26369/26369 [==============================] - 360s 14ms/step - loss: 1.3708 - mae: 1.3707 - val_loss: 1.4415 - val_mae: 1.4417\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_normalized(actual, pred):\n",
    "    n = tf.shape(actual)[1]\n",
    "    indices = tf.nn.top_k(pred, k=n)[1][0]\n",
    "    actual_sorted = tf.gather(actual[0], indices)\n",
    "    cost = tf.reduce_sum(actual_sorted)\n",
    "    loss_proportion = tf.cumsum(actual_sorted) / cost\n",
    "    null_model = tf.compat.v1.to_double(tf.range(1, n + 1)) / tf.compat.v1.to_double(n)\n",
    "    g = tf.subtract(loss_proportion, null_model)\n",
    "    g = tf.reduce_sum(g) / tf.compat.v1.to_double(n)\n",
    "    g /= (1.0 - tf.reduce_mean(actual)) / 2.0\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8241/8241 [==============================] - 70s 8ms/step - loss: 1.2847 - mae: 1.2848\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(df_to_dataset(test, test_target, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(df_to_dataset(test, test_target, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07326340098358843\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.transpose(np.array([r if r[0] > 0 else [0] for r in result]))\n",
    "y_true = np.transpose(np.array([[t] for t in test_target.values]))\n",
    "score = gini_normalized(y_true,y_pred)\n",
    "\n",
    "print(score.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_features_1 (DenseFeatu multiple                  801619    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  31680     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  65        \n",
      "=================================================================\n",
      "Total params: 837,524\n",
      "Trainable params: 837,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
